---
title: "Report ML Project"
author: "Martin Hediger"
date: "21. Februar 2015"
output: html_document
---

```{r cache=TRUE, echo=FALSE}
if(!file.exists("./pml-training.rds"))
{
    training <- read.csv("pml-training.csv", header=T)
    saveRDS(training, file="./pml-training.rds")
    rm(ls="training")
}
training_data <- readRDS("./pml-training.rds")
library(caret)
```

# Introduction
Using a training data set obtained from Velloso *et al.*, a model was trained such that it could recognize the quality of physical training exercises.
*I.e.* the model can recognize if an exercise is carried out according to instructions or not.

# Cleaning Data / Preprocessing
Training and testing data was obtained from the course homepage in raw format.
The data has `r length(names(training))` variables (including the one classification variable `classe` which should be predicted in using the testing data).  
For cross-validated training, the training data was subdivided into a training and a testing set.
```{r cache=TRUE}
inTrain <- createDataPartition(y=training_data$classe, p=0.7, list=FALSE)
training <- training_data[inTrain, ]
testing <- training_data[-inTrain, ]
```
Initial analysis revealed that a number of describing variables were present in the dataset.
```{r cache=TRUE}
training_numeric <- training[sapply(training, is.numeric)]
```
Furthermore, variables specifying only one coordinate (`x`, `y` or `z`) of a feature were discarded.
Finally, only features of `numeric` or `integer` class remained in the `red`uced data set.
```{r cache=TRUE}
red <- training_numeric[ c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt",
                           "roll_arm", "pitch_arm", "yaw_arm", "total_accel_arm",
                           "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell",
                           "total_accel_dumbbell",
                           "roll_forearm", "pitch_forearm", "yaw_forearm",
                           "total_accel_forearm")]
```

The `classe` variable however had to be reattached to the data set.
For an unkown reason, the rebinded `classe` variable had to be renamed.
```{r cache=TRUE}
red <- cbind(red, training[inTrain, "classe"])
colnames(red)[17] <- "classe"
names(red)
```

Also it was checked if any `NA` values remained in the data set which would require missing value imputation.
```{r}
for(i in 1:length(names(red))-1){print(paste(names(red)[i], any(is.na(red[[1]]))))}
```
The working data set for training was now prepared.

# Exploratory Analysis
Exploratory analysis was carried out but the findings are not conclusive.

```{r echo=FALSE, cache=TRUE, fig.height=4, fig.width=10}
library(ggplot2)
library(gridExtra)
p_roll_belt <- qplot(y=red$roll_belt, color=red$classe)
p_pitch_belt <- qplot(y=red$pitch_belt, color=red$classe)
grid.arrange(p_roll_belt, p_pitch_belt, ncol=2)
```

The fact that the `classe`s are separated by the sequence index might indicate that a time variable is present.
This is indeed also stated in the data set description given by the study authors but is not further studied.

# Model Building and Prediction
The model built for classification was based on training with random forest classification, cross-validation was done using the `trControl=trainControl(method="cv", number=25)` argument to the `train` function.
```{r cache=TRUE}
# Preprocess and train.
if(file.exists("./modelFitPrepCVRF.rda"))
{ 
    load("./modelFitPrepCVRF.rda")
} else {
    modelFitPrepCVRF <- train(classe ~Â .,
                              data=red,
                              preProcess=c("center", "scale"),
                              trControl=trainControl(method="cv", number=25),
                              method="rf")
    save(modelFitPrepCVRF, file="./modelFitPrepCVRF.rda")
}
```
It is important to note that preprocessing by `center` and `scale` is required, otherwise training does not converge.
The accuracy of 25-fold cross-validating model using a random forest training and `mtry` of 9 was around 0.96.
```{r}
modelFitPrepCVRF
```

The error rate for new data (= out of sample error) is calculated as
```{r cache=TRUE}
modelFitPrepCVRF$finalModel
```
to be around 2.96 %.
